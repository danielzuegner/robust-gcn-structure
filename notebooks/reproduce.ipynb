{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from robust_gcn_structure.certification import certify\n",
    "from robust_gcn_structure.utils import load_npz\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"citeseer\"\n",
    "robust_gcn = True  # Whether to load weights for GCN trained with the approach by [Zügner and Günnemann 2019\n",
    "\n",
    "local_budget = 3\n",
    "global_budget = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our experiments, the solver ECOS fails with an error in some instances, which does not happen with CPLEX.\n",
    "# In case of an error we report non-robustness, therefore ECOS numbers are slightly lower than the CPLEX numbers\n",
    "# reported in the paper.\n",
    "solver = \"ECOS\"  # CPLEX is faster but is proprietary and not installed by default.\n",
    "max_iters = 250\n",
    "tolerance = 1e-2\n",
    "kwargs = {\n",
    "    'tolerance': tolerance,\n",
    "    'max_iter': max_iters\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "A, X, z = load_npz(f'../datasets/{dataset}.npz')\n",
    "A = A + A.T\n",
    "A[A > 1] = 1\n",
    "A.setdiag(0)\n",
    "\n",
    "X = (X>0).astype(\"float32\")\n",
    "z = z.astype(\"int64\")\n",
    "N, D = X.shape\n",
    "\n",
    "# Load weights\n",
    "weight_path = f\"../pretrained_weights/{dataset}\"\n",
    "if robust_gcn:\n",
    "    weight_path = f\"{weight_path}_robust_gcn.pkl\"\n",
    "else:\n",
    "    weight_path = f\"{weight_path}_gcn.pkl\"\n",
    "\n",
    "state_dict = torch.load(weight_path, map_location=\"cpu\")\n",
    "\n",
    "weights = [v for k,v in state_dict.items() if \"weight\" in k and \"conv\" in k]\n",
    "biases = [v for k,v in state_dict.items() if \"bias\" in k and \"conv\" in k]\n",
    "\n",
    "W1, W2 = [w.cpu().detach().numpy() for w in weights]\n",
    "b1, b2 = [b.cpu().detach().numpy() for b in biases]\n",
    "\n",
    "shapes = [x.shape[0] for x in biases]\n",
    "num_hidden = len(shapes) - 1\n",
    "if num_hidden > 1:\n",
    "    raise NotImplementedError(\"Only one hidden layer is supported.\")\n",
    "\n",
    "weight_list = [W1, b1, W2, b2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives exactly the 500 nodes that we sampled for our experiments.\n",
    "np.random.seed(481516)\n",
    "eval_nodes = np.random.choice(np.arange(0, A.shape[0]), 500, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fct(target_node):\n",
    "    return certify(target_node, A, X, weight_list, z,\n",
    "                      local_changes=local_budget,\n",
    "                      global_changes=global_budget,\n",
    "                      solver=solver, eval_class=None,\n",
    "                      use_predicted_class=True, **kwargs)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(processes=processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness_results = []\n",
    "errors = []\n",
    "with tqdm(total=len(eval_nodes)) as pbar:\n",
    "    for i, res in enumerate(pool.imap_unordered(fct, eval_nodes)):\n",
    "        robustness_results.append(res['all_robust'])\n",
    "        infs = False\n",
    "        err = False\n",
    "        for k,v in res.items():\n",
    "            if type(v) != dict:\n",
    "                continue\n",
    "            if 'error' in v:\n",
    "                err = err or v['error']\n",
    "        infeasible.append(infs)\n",
    "        errors.append(err)\n",
    "\n",
    "        pbar.update()\n",
    "        pbar.set_postfix(robust=np.mean(robustness_results), \n",
    "                         errors=np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(robustness_results) + np.mean(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(robustness_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (1.1 new)",
   "language": "python",
   "name": "torch_1_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
